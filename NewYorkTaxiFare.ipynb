{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e395d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\ML\\\\NewYorkTaxi_Jupyter'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2042a317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2009-06-15 17:26:21 UTC\n",
      "1    2010-01-05 16:52:16 UTC\n",
      "2    2011-08-18 00:35:00 UTC\n",
      "3    2012-04-21 04:30:42 UTC\n",
      "4    2010-03-09 07:51:00 UTC\n",
      "Name: pickup_datetime, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "training = pd.read_csv('data/train.csv', nrows=100)\n",
    "test = pd.read_csv('data/test.csv', nrows=100)\n",
    "\n",
    "pd.set_option('display.max_columns',10)\n",
    "pd.set_option('display.width', 100)\n",
    "\n",
    "print(training.pickup_datetime.head())\n",
    "type(training)\n",
    "\n",
    "training.isnull().values.any()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f388f2c",
   "metadata": {},
   "source": [
    "We need to write a custom function for cross validation.\n",
    "\n",
    "Ideas:\n",
    "0- Check for empty and null values\n",
    "1- Simplify pick time to a number between 0 to 24 to just represent time of the day\n",
    "2- Come up with a new column that shows the distance. This may not be great since the exact locations may affect the length of the trip that could affect the fare.\n",
    "3- Check for linear correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9dd7623",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m training \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, on_bad_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m'\u001b[39m, nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m) \u001b[38;5;66;03m# TODO remove limit\u001b[39;00m\n\u001b[0;32m      2\u001b[0m test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData loaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "training = pd.read_csv('data/train.csv', on_bad_lines='skip', nrows=5000) # TODO remove limit\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(\"Data loaded.\")\n",
    "print(\"Read \" + str(len(training)) + \" training rows\")\n",
    "print(\"Read \" + str(len(test)) + \" test rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480a7d76",
   "metadata": {},
   "source": [
    "Now we break apart the pickup times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "346dc52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
      "0          4.5        -73.844311        40.721319         -73.841610         40.712278   \n",
      "1         16.9        -74.016048        40.711303         -73.979268         40.782004   \n",
      "2          5.7        -73.982738        40.761270         -73.991242         40.750562   \n",
      "3          7.7        -73.987130        40.733143         -73.991567         40.758092   \n",
      "4          5.3        -73.968095        40.768008         -73.956655         40.783762   \n",
      "\n",
      "   passenger_count  pickup_year  pickup_month  pickup_day  pickup_hour  pickup_minute  \\\n",
      "0                1         2009             6          15           17             26   \n",
      "1                1         2010             1           5           16             52   \n",
      "2                2         2011             8          18            0             35   \n",
      "3                1         2012             4          21            4             30   \n",
      "4                1         2010             3           9            7             51   \n",
      "\n",
      "   pickup_dayofweek  \n",
      "0                 0  \n",
      "1                 1  \n",
      "2                 3  \n",
      "3                 5  \n",
      "4                 1  \n",
      "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
      "0        -73.973320        40.763805         -73.981430         40.743835                1   \n",
      "1        -73.986862        40.719383         -73.998886         40.739201                1   \n",
      "2        -73.982524        40.751260         -73.979654         40.746139                1   \n",
      "3        -73.981160        40.767807         -73.990448         40.751635                1   \n",
      "4        -73.966046        40.789775         -73.988565         40.744427                1   \n",
      "\n",
      "   pickup_year  pickup_month  pickup_day  pickup_hour  pickup_minute  pickup_dayofweek  \n",
      "0         2015             1          27           13              8                 1  \n",
      "1         2015             1          27           13              8                 1  \n",
      "2         2011            10           8           11             53                 5  \n",
      "3         2012            12           1           21             12                 5  \n",
      "4         2012            12           1           21             12                 5  \n"
     ]
    }
   ],
   "source": [
    "def convert_pickup_times(df):\n",
    "    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], format='%Y-%m-%d %H:%M:%S UTC', errors='coerce')\n",
    "\n",
    "def break_pickup_times_to_components(df):\n",
    "    df['pickup_year'] = df['pickup_datetime'].dt.year\n",
    "    df['pickup_month'] = df['pickup_datetime'].dt.month\n",
    "    df['pickup_day'] = df['pickup_datetime'].dt.day\n",
    "    df['pickup_hour'] = df['pickup_datetime'].dt.hour\n",
    "    df['pickup_minute'] = df['pickup_datetime'].dt.minute\n",
    "    #converting seconds sounds like an overkill so I won't use it\n",
    "    \n",
    "    #but day of week sounds like a predictive feature\n",
    "    df['pickup_dayofweek'] = df['pickup_datetime'].dt.dayofweek\n",
    "    \n",
    "    #remove the redundant col\n",
    "    df.drop(columns=['pickup_datetime'], inplace=True)\n",
    "\n",
    "def prepare(df):\n",
    "    convert_pickup_times(df)\n",
    "    break_pickup_times_to_components(df)\n",
    "    df.drop(columns=['key'], inplace=True)\n",
    "    \n",
    "prepare(training)\n",
    "prepare(test)\n",
    "\n",
    "pd.set_option('display.max_columns',16)\n",
    "pd.set_option('display.width', 100)\n",
    "print(training.head())\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d334e320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26eb4d1c",
   "metadata": {},
   "source": [
    "Since the number of cells with null value is relatively small and there's no null values in the test data we can just drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2249805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "499995 rows\n"
     ]
    }
   ],
   "source": [
    "def check_for_nulls(df):\n",
    "    is_null = df.isnull()\n",
    "    row_has_null = is_null.any(axis=1)\n",
    "    print(row_has_null.sum())\n",
    "    \n",
    "check_for_nulls(training)\n",
    "check_for_nulls(test)\n",
    "\n",
    "training = training[~training.isnull().any(axis=1)]\n",
    "print(str(len(training)) + \" rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6d33d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was split into features and labels.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "\n",
    "def custom_cross_validation(cv, x_train, y_train, model):\n",
    "    pie_len = len(x_train) / cv\n",
    "    total_len = len(x_train)\n",
    "    for i in range(0, cv):\n",
    "        b = int(i * pie_len)\n",
    "        e = int(b + pie_len)\n",
    "        train_range = np.r_[0:b, e:total_len]\n",
    "        test_range = np.r_[b:e]\n",
    "        model.fit(x_train[train_range], y_train[train_range])\n",
    "        predictions = model.predict_proba(x_train[test_range])\n",
    "\n",
    "        rmse = mean_squared_error(y_train[test_range], predictions, squared=False)\n",
    "\n",
    "        print(rmse)\n",
    "\n",
    "X = training.iloc[:, training.columns != 'fare_amount'].values\n",
    "y = training.iloc[:, training.columns == 'fare_amount'].values.ravel()\n",
    "\n",
    "print(\"Data was split into features and labels.\")\n",
    "\n",
    "regr = svm.SVR()\n",
    "\n",
    "custom_cross_validation(5, X, y, regr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7133ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53f0a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b14644d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
